Using the openModeller command line tools
-----------------------------------------

This directory contains examples to demonstrate how the 
various om_* command line tools can be used. They use the 
simplest case scenario of a bioclim model with a couple of
environmental layers - subsequently the models produced 
themselves are not particularly robust or interesting. Rather
the idea is that you examine the configuration files provided
and available parameters to decide how to prepare your own 
models.

Note: Since the sample request files provided (request.txt, 
model_request.xml, projection_request.xml and test_request.xml)
have references to other files, when using them you should run 
the command-line tools from inside the "examples" directory.

---

1) om_console

om_console takes a simple text file as listed in request.txt

e.g.

om_console request.txt

---

2) om_viewer

If you have built with X11 support you can use the om_viewer 
program to visualise the distribution map generated by 
openModeller:

e.g.

om_viewer -r request.txt

Or visualise the maps that were used to build the model:

e.g.

om_viewer request.txt

---

3) om_niche

If you have built with X11 support and if your experiment has only 
two input layers, you can use the om_niche program to visualize the 
model as a graphic showing probabilities in the environmental space.
Just pass the serialized model as a parameter.

e.g.

om_niche -o furcata.xml

---

4) om_sampler

When openmodeller creates a model, it fetches the values
through each of the climate layers. This is known as a sample. The
sample at each presence (or absence) point can be obtained using 
the om_sampler application. This is useful if you want to under-
stand the actual data being used to build the model.

e.g.

om_sampler --source request.txt

---

5) om_model

This program uses the newer XML format for describing how a model
should be built. The output is another XML file which contains
the serialised model. No projection (mapping) of the model is 
carried out (see om_project below). This is useful if you wish
to create a model and project it into numerous climate scenarios.
om_console can produce a simlar result using the 'Output model'
instruction in the request file. om_model is a wholly XML 
approach to this.

e.g.

om_model --xml-req model_request.xml --model-file acacia_model.xml

(acacia_model.xml is the output model file)

Additional parameters and detailed documentation can be found in the
corresponding man page, or just by typing om_model without parameters.

---

6) om_test

This program can be used to perform external tests in models. The
input can be either a specific XML request for testing a model, or
a serialized model and a file with the points to be tested. 
The output is another XML file which contains the test result.

e.g.

om_test --xml-req test_request.xml

or

om_test --model acacia_model.xml --points test_points.txt --calc-matrix

(acacia_model.xml is the same file generated by the om_model example)

Additional parameters and detailed documentation can be found in the
corresponding man page, or just by typing om_test without parameters.

---

7) om_project

This program is used to project a serialized model into an 
environment scenario. The output will be an image showing 
a probability surface.

There are two ways to use om_project. The first one is to specify
an XML file that describes how the projection should be built (see
projection_request.xml for an example). In this case the projection
layers can be different from the layers used to create the model.
However, note that there must be a match between each layer used to 
originally build the model and each layer in the projection 
environment:

 Create Model           Project Model
 ------------------------------------
 temp             |     temp_2
 rainfall         |     rainfall_2
 etc              |     etc

The second way to use om_project is to specify a serialized model. 
This can only be used with native projections, i.e., the same layers
that were used to create the model will be used in the projection. 

In either way, it is always necessary to also specify the name of the 
distribution map that will be generated. Optional statistics file and 
log file can be saved as well.

e.g.

om_project --xml-req projection_request.xml --dist-map furcata.img

or 

om_project --model acacia_model.xml --dist-map acacia.img

Additional parameters and detailed documentation can be found in the
corresponding man page, or just by typing om_project without parameters.

---

8) om_algorithm

This program can be used to get more information about the available 
algorithms.

e.g.

om_algorithm --list

Additional parameters and detailed documentation can be found in the
corresponding man page, or just by typing om_algorithm without parameters.

---

9) om_points

This program can be used to read occurrence data from a specified source
and return it as tab-delimited or XML content. 

e.g.

om_points --source http://data.gbif.org/ws/rest/occurrence/list --name "Physalis peruviana"

Additional parameters and detailed documentation can be found in the
corresponding man page, or just by typing om_points without parameters.

---

10) om_pseudo

This program can be used to generate pseudo occurrences.

e.g.

om_pseudo --num-points 20 --mask rain_coolest.tif

or

om_pseudo --xml-req sample_request.xml --result sampled_points.xml

Additional parameters and detailed documentation can be found in the
corresponding man page, or just by typing om_pseudo without parameters.

---

11) om_evaluate

This program can be used to return raw model values.

e.g.

om_evaluate --model acacia_model.xml --points test_points.txt

or

om_evaluate --xml-req test_request.xml

Additional parameters and detailed documentation can be found in the
corresponding man page, or just by typing om_evaluate without parameters.

-----------------------------------------------------------------------

ADDITIONAL INFORMATION

If you are a developer interested in performance optimization (and has 
enough bandwidth to download ~3.5G of data), you can follow the steps
below to run an experiment using several high resolution environmental
layers, thousands of points and an algorithm that can take quite some
time to run.

In the examples/ directory, there is a little script to download all the
necessary files, including environmental layers from WorldClim,
occurrence points and a request file ready to use with openModeller:

$ getperftests.sh

If you use another platform without Bash, instead of using the script 
above you can manually create the directory perftests/, download and 
extract the environmental layers inside it:

http://biogeo.ucdavis.edu/data/climate/worldclim/1_4/grid/cur/tmin_30s_esri.zip
http://biogeo.ucdavis.edu/data/climate/worldclim/1_4/grid/cur/tmax_30s_esri.zip
http://biogeo.ucdavis.edu/data/climate/worldclim/1_4/grid/cur/prec_30s_esri.zip

Then download the occurrence points:

http://openmodeller.cria.org.br/download/examples/all_points_1.txt

And finally the request file:

http://openmodeller.cria.org.br/download/examples/req_1.txt

If all went well (e.g. the files downloaded aren't corrupted) you can run the 
experiment inside perftests/ directory with om_console.

$ cd perftests
$ om_console req_1.txt

Similar tests can be run using the other command-line tools (points were split 
into test and training using 0.5 proportion to generate the following requets).
In this case, you should download a model request in XML:

http://openmodeller.cria.org.br/download/examples/model_req_1.xml

The set of testing points:

http://openmodeller.cria.org.br/download/examples/test_1.txt

And then run the command-line programs in the following order:

$ om_model -r model_req_1.xml -m model_1.xml --log-file logm_1.txt --prog-file progm_1.txt

$ om_test -o model_1.xml -p test_1.txt --log-file logt_1.txt --prog-file progt_1.txt

$ om_project -o model_1.xml -m proj_1.img --stat-file stat_1.xml --log-file logp_1.txt --prog-file progp_1.txt
